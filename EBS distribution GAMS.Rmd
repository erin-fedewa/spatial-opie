---
title: "EBS distribution gams"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE}

library(mgcv)
library(dplyr)
library(ggplot2)

d = read.csv("ebs trawl taxa per Kotwicki & Lauth.csv")
d = d[which(d$bottom.temp > -10),] # so this drops NAs for bottom temp?
d$logdepth = log(d$depth)

output = data.frame("year" = unique(d$year))
output_bin = data.frame("year" = unique(d$year))

spp.list = names(d)[2:23]

# covariates: lat, long, bottom.temp, depth, year, julian

for(i in 1:length(spp.list)) {

# fit simple spatial GAM with field varying by year
d$abund = d[,spp.list[i]]

# fit delta-glm
d$pres = ceiling(d$abund/1.0e10)
model_bin = gam(pres ~ te(lat, long) + as.factor(year) +
    bottom.temp + logdepth + julian + I(bottom.temp^2) +
    I(logdepth^2) + I(julian^2), data=d, family="binomial") #ML: why the different link functions?

model_dens = gam(abund ~ te(lat, long) + as.factor(year) +
    bottom.temp + logdepth + julian + I(bottom.temp^2) +
    I(logdepth^2) + I(julian^2), data=d[which(d$abund>0),], family="Gamma")

# only project to the same years in both datasets
years = model_dens$xlevels$`as.factor(year)`[which(model_dens$xlevels$`as.factor(year)` %in% model_bin$xlevels$`as.factor(year)`)]

df_new = expand.grid("lat" = seq(quantile(d$lat, 0.025),
  quantile(d$lat, 0.975), length.out=100),
  "long" = mean(d$long),
  "year" = as.numeric(years),
  "bottom.temp" = mean(d$bottom.temp),
  "logdepth" = mean(d$logdepth),
  "julian" = mean(d$julian))

# predict to new data frame
df_new$predbin = predict(model_bin,
  newdata = df_new, type="response")

df_new$predpos = predict(model_dens,
  newdata = df_new, type="response")
df_new$pred = df_new$predbin * df_new$predpos # total

# calculate weighted average of latitude, with weights = density
g1 = group_by(df_new, year) %>%
  summarize(meanLat = weighted.mean(x = lat, w = pred),
    meanPres = mean(predbin))

if(i==1) {
  output = data.frame("spp"= spp.list[i], "lat" = c(g1$meanLat), stringsAsFactors = FALSE)
  output_bin = data.frame("spp"= spp.list[i], "lat" = c(g1$meanPres), stringsAsFactors = FALSE)
}
if(i > 1) {
  output = rbind(output, data.frame("spp"= spp.list[i], "lat" = c(g1$meanLat), stringsAsFactors = FALSE))
  output_bin = rbind(output_bin, data.frame("spp"= spp.list[i], "lat" = c(g1$meanPres), stringsAsFactors = FALSE))
}
#g1 = ggplot(g1, aes(year, meanLat)) + geom_line() +
#  geom_point() + ggtitle(spp.list[i])
#print(g1)
}

library(ggplot2)
library(ggsidekick)
output = group_by(output, spp) %>%
  mutate(years=rev(rev(1982:2016)[1:length(lat)]))

# save output
write.csv(output, "GAM center of gravity all stations.csv")
# ggplot(output, aes(x=years, y = lat)) + geom_line() + geom_point(size=0.4) +
#   facet_wrap(~spp, scale="free_y") + theme_sleek() + xlab("Year") +
#   ylab("Model - based center of gravity") + theme(strip.text.x = element_text(size = 4))


ggplot(output, aes(x=years, y = lat)) + geom_line() + geom_point(size=0.4) +
  facet_wrap(~spp, scale="free_y") +  xlab("Year") +
  ylab("Model - based center of gravity") + theme(strip.text.x = element_text(size = 4))

```

Now that's the result for all stations. We can compare with results derived only from stations sampled in every year.

```{r, echo=FALSE}
# reload
d = read.csv("ebs trawl taxa per Kotwicki & Lauth.csv")
# replace -9999 with NA!
mm <- d$bottom.temp == -9999
d$bottom.temp[mm] <- NA

# st is the list of stations sampled in every year, from the Sea Grant project
d2 <- d[d$station %in% st,]

# and check
check <- tapply(d2$lat, d2$station, function(x) sum(!is.na(x)))
# J-13 has 36 observations!

check <- filter(d2, station =="J-13")
check # two in 1988, on the same day!

check <- filter(d2, station=="J-13", year==1988)

replace <- colMeans(check[,1:29])

# drop the duplicates
drop <- d2$year==1988 & d2$station=="J-13"

d2 <- d2[!drop,]
nrow(d2)
d2[9975,] <- NA
d2[9975,1:29] <- replace
d2[9975,30] <- "J-13" 

# check for missing temperatures
temp <- tapply(d2$bottom.temp, list(d2$year, d2$station), mean)
jj <- d2$station %in% st

# drop the empty columns!
j <- apply(temp, 2, function(x) sum(is.na(x)))
table(j)
jj <- j<35
temp <- temp[,jj]

# fill missing values with mice!
require(mice)
require(Hmisc)

# Determine "best" predictor variables for each column:
r <- rcorr(temp)$r

# Choose 20 variables with highest absolute correlation (van Buuren & Oudshoorn recommend 15-25)
pred <- t(apply(r,1, function(x) rank(1-abs(x))<=20))
diag(pred) <- FALSE

Ni <- 100 # number of imputations
imp <- mice(temp, Ni, imp="norm", predictor = pred)

#calculate mean and sd values from 100 imputations in final iteration
MI.sd <- MI.mean <- matrix(nrow = nrow(temp), ncol = ncol(temp))
dimnames(MI.sd) <- dimnames(MI.mean) <- dimnames(temp)

for(j in 1:ncol(temp)) { # go through each variable separately
#j <- 2
tt <- matrix(NA, nrow = nrow(temp), ncol = Ni)
for(i in 1:Ni) { # and go through each imputation
a <- complete(imp, i)
tt[,i] <- a[,j]
	}
MI.mean[,j] <- rowMeans(tt)
MI.sd[,j] <- apply(tt, 1, sd)
	}

# ok, now we need to replace the NAs!

mm <- is.na(d2$bottom.temp)
sum(mm) # 415 missing!

st.MI <- stack(as.data.frame(MI.mean))
st.MI$year <- 1982:2016
st.MI

d2 <- d2[order(d2$year),]
d2 <- d2[order(d2$station),]

identical(as.character(d2$station), as.character(st.MI$ind)) # TRUE!
identical(as.numeric(d2$year), as.numeric(st.MI$year)) # T!

d2$bottom.temp <- st.MI$values

  
# ok, should be ready to rumble!  
```

```{r, echo=T}
# re-run the script!

d2$logdepth = log(d2$depth)

output2 = data.frame("year" = unique(d2$year))
output_bin2 = data.frame("year" = unique(d2$year))

spp.list = names(d2)[2:23]

# covariates: lat, long, bottom.temp, depth, year, julian

for(i in 1:length(spp.list)) {

# fit simple spatial GAM with field varying by year
d2$abund = d2[,spp.list[i]]

# fit delta-glm
d2$pres = ceiling(d2$abund/1.0e10)
model_bin = gam(pres ~ te(lat, long) + as.factor(year) +
    bottom.temp + logdepth + julian + I(bottom.temp^2) +
    I(logdepth^2) + I(julian^2), data=d2, family="binomial") 

model_dens = gam(abund ~ te(lat, long) + as.factor(year) +
    bottom.temp + logdepth + julian + I(bottom.temp^2) +
    I(logdepth^2) + I(julian^2), data=d2[which(d2$abund>0),], family="Gamma")

# only project to the same years in both datasets
years = model_dens$xlevels$`as.factor(year)`[which(model_dens$xlevels$`as.factor(year)` %in% model_bin$xlevels$`as.factor(year)`)]

df_new = expand.grid("lat" = seq(quantile(d2$lat, 0.025),
  quantile(d2$lat, 0.975), length.out=100),
  "long" = mean(d2$long),
  "year" = as.numeric(years),
  "bottom.temp" = mean(d2$bottom.temp),
  "logdepth" = mean(d2$logdepth),
  "julian" = mean(d2$julian))

# predict to new data frame
df_new$predbin = predict(model_bin,
  newdata = df_new, type="response")

df_new$predpos = predict(model_dens,
  newdata = df_new, type="response")
df_new$pred = df_new$predbin * df_new$predpos # total

# calculate weighted average of latitude, with weights = density
g1 = group_by(df_new, year) %>%
  summarize(meanLat = weighted.mean(x = lat, w = pred),
    meanPres = mean(predbin))

if(i==1) {
  output2 = data.frame("spp"= spp.list[i], "lat" = c(g1$meanLat), stringsAsFactors = FALSE)
  output_bin2 = data.frame("spp"= spp.list[i], "lat" = c(g1$meanPres), stringsAsFactors = FALSE)
}
if(i > 1) {
  output2 = rbind(output2, data.frame("spp"= spp.list[i], "lat" = c(g1$meanLat), stringsAsFactors = FALSE))
  output_bin2 = rbind(output_bin2, data.frame("spp"= spp.list[i], "lat" = c(g1$meanPres), stringsAsFactors = FALSE))
}
#g1 = ggplot(g1, aes(year, meanLat)) + geom_line() +
#  geom_point() + ggtitle(spp.list[i])
#print(g1)
}

library(ggplot2)
# library(ggsidekick)
output2 = group_by(output2, spp) %>%
  mutate(years=rev(rev(1982:2016)[1:length(lat)]))

# save output2
write.csv(output2, "GAM center of gravity all stations.csv")
# ggplot(output2, aes(x=years, y = lat)) + geom_line() + geom_point(size=0.4) +
#   facet_wrap(~spp, scale="free_y") + theme_sleek() + xlab("Year") +
#   ylab("Model - based center of gravity") + theme(strip.text.x = element_text(size = 4))


ggplot(output2, aes(x=years, y = lat)) + geom_line() + geom_point(size=0.4) +
  facet_wrap(~spp, scale="free_y") +  xlab("Year") +
  ylab("Model - based center of gravity") + theme(strip.text.x = element_text(size = 4))


```